# MNIST Fully Connected Network Tuning

## Описание проекта
В данном проекте проводится исследование различных гиперпараметров нейронной сети для классификации изображений рукописных цифр из набора данных MNIST. Целью работы является определение оптимальных параметров модели, которые обеспечат наилучшие результаты на тестовых данных.

## Содержание
- [1. Введение](#1-введение)
- [2. Загрузка данных](#2-загрузка-данных)
- [3. Построение модели](#3-построение-модели)
- [4. Исследование гиперпараметров](#4-исследование-гиперпараметров)
- [5. Результаты](#5-результаты)
- [6. Заключение](#6-заключение)

## 1. Введение
Набор данных MNIST состоит из 70,000 изображений рукописных цифр, размером 28x28 пикселей. Данные разбиты на обучающую (60,000) и тестовую (10,000) выборки. В данной работе мы исследуем влияние различных гиперпараметров на качество модели.

## 2. Загрузка данных
После загрузки данные разделяются на обучающую и тестовую выборки.

## 3. Построение модели
Мы используем полносвязную нейронную сеть с одним скрытым слоем. Модель включает следующие компоненты:
- Входной слой
- Скрытый слой с активацией ReLU
- Выходной слой с активацией Softmax

## 4. Исследование гиперпараметров
В рамках проекта исследуются следующие гиперпараметры:
- **Количество нейронов в скрытом слое**
- **Количество эпох обучения**
- **Функции активации** (ReLU, Sigmoid)
- **Регуляризация** (Dropout)
- **Инициализация весов**
- **Нормализация по мини-батчам**
- **Методы градиентного спуска** (SGD, Adam) и их адаптивные версии

## 5. Результаты
Будут представлены результаты всех экспериментов, а именно значения гиперпараметров и достигнутая точность модели на тестовых данных.

## 6. Заключение
Проект демонстрирует, как различные настройки гиперпараметров могут влиять на производительность нейронной сети.
